test -e "$REPO_PIGLIT/piglit" || return 1

function __piglit_gen_report__ {
    # generate a report, first print the passrate on the first line, then print the individual results
    python3 - 2> ${run_log_file}.processing_stderr << END
import traceback
import sys
import six

sys.path.append("$REPO_PIGLIT")
from framework import summary, status, core, backends, exceptions
from framework.programs import parsers

tests=list()
pass_count = 0

try:
    testrun = backends.load("${piglit_output}")

    for name, result in six.iteritems(testrun.tests):
        for key, value in six.iteritems(result.subtests):
            tests.append("{}<{}>: {}".format(name, key, value))
            if value == 'pass':
                pass_count += 1
        tests.append("{}: {}".format(name, result.result))
        if result.result == 'pass':
            pass_count += 1
except Exception as e:
    traceback.print_exc(file=sys.stderr)

if len(tests) > 0:
    print("{:.3f}".format(pass_count / len(tests)))
else:
    print("0")
for test in tests:
    print(test)
END

    local exit_code=$?

    # Go through all the subtests we wanted to get and check if all of them
    # are present. If not, mark them as missing.
    for subtest in "${run_sub_tests[@]}"; do
        grep "$subtest" "$run_log_file" 2> /dev/null > /dev/null
        [ $? -eq 1 ] && echo "$subtest: missing"
    done

    # Display the final status, if it was a full run
    if [ "$exit_code" -eq 0 ] && [ ! -f "${run_log_file}.testlist" ]; then
        echo ": completed"
    fi

    # delete or move the report
    if [ "$PIGLIT_KEEP_REPORTS" -eq 1 ]; then
        mv "${piglit_output}" "${run_log_file}_done"
    else
        rm -rf "${piglit_output}" 2>&1
    fi

    return 0
}

function __piglit_resume__ {
    cd "$REPO_PIGLIT"

    # verify that the run is indeed resumable
    local piglit_output="${run_log_file}_tmp"
    [ -d "$piglit_output" ] || return 19

    # Only try to resume if it is still possible to resume, otherwise, just
    # generate the report
    if [ -f "$piglit_output/metadata.json" ]; then
        # ignore the incomplete result to avoid being stuck in a loop
        local cmdline="$REPO_PIGLIT/piglit resume -n '$piglit_output'"

        # Start the debug console
        if hash xterm; then
            xterm -geometry +0+300 -e "echo $cmdline; tail -n1 -F \"$run_log_file.stdout\""&
            xterm_pid=$!
        fi

        ENV_DUMP_RESTRICT_TO_BINARY="NO_ENVDUMP_PLEASE" \
        $cmdline >> "$run_log_file.stdout" 2>> "$run_log_file.stderr"
        local exit_code=$?

        # Kill the debug console
        [ -n "$xterm_pid" ] && kill $xterm_pid

        # piglit resume returns 1 if we try to resume a report that is already done
        if [ $exit_code -ne 0 ]; then
            __piglit_resume__
        fi
    fi

    __piglit_gen_report__
}

function __piglit_run__ {
    cd "$REPO_PIGLIT"

    local test_name=${testNames[$t]}
    local backend=$1
    local testscript=$2

    # Sub tests
    local has_subtests=0
    local testlist=''
    local testlistfile="${run_log_file}.testlist"
    rm "$testlistfile" 2> /dev/null
    for subtest in "${run_sub_tests[@]}"; do
        echo "$subtest" | cut -d '<' -f 1 >> $testlistfile
        has_subtests=1
    done
    [ $has_subtests -eq 1 ] && testlist="--test-list $testlistfile"

    # start piglit. Use the sync mode to make the resume more reliable
    piglit_output=${run_log_file}_tmp
    local cmdline="$REPO_PIGLIT/piglit run -p $backend $PIGLIT_RUN_PARAMS -s $testlist $testscript ${piglit_output}"

    # Start the debug console
    if hash xterm; then
        xterm -geometry +0+300 -e "echo $cmdline; tail -F \"$run_log_file.stdout\""&
        xterm_pid=$!
    fi

    ENV_DUMP_REQUIRE_ARGUMENT="$REPO_PIGLIT/piglit" \
    ENV_DUMP_NO_METRICS=1 \
    run_bench 0 $cmdline > /dev/null 2> /dev/null
    local exit_code=$?

    # Kill the debug console
    [ -n "$xterm_pid" ] && kill $xterm_pid

    if [ $exit_code -ne 0 ]; then
        __piglit_resume__
    else
        __piglit_gen_report__
    fi
}

backends=$($REPO_PIGLIT/piglit run -h | grep "^  -p" | cut -d '{' -f 2 | cut -d '}' -f 1 | tr ',' ' ')
for backend in $backends; do
    for test_script in $REPO_PIGLIT/tests/*.py; do
        [ "$(basename $test_script)" == "__init__.py" ] && continue
        [ "$(basename $test_script)" == "igt.py" ] && continue

        name="piglit:$backend:$(basename ${test_script} | cut -d '.' -f 1)"
        eval "${name}_run() { __piglit_run__ $backend $test_script \$@;}"
        eval "${name}_resume() { __piglit_resume__;}"
        test_name="$test_name $name"
    done
done

test_unit="pass/total"
test_type="unit"
test_exec_time=600
test_has_exit_code=1
